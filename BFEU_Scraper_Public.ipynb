{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perelloliver/BuyFromEU-Reddit-Scraper/blob/main/BFEU_Scraper_Public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL_u1AHY-JxQ"
      },
      "source": [
        "# 1. Enter required details for API access\n",
        "client_id and client_secret can be acquired from the reddit project, ask Oliver to add you\n",
        "\n",
        "user_agent_input is our project name + your username, just a message so admins can contact you if anything goes wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qShUcIDh-NHd"
      },
      "outputs": [],
      "source": [
        "client_id_input = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Input your client ID\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K8yzNbdw-V8p"
      },
      "outputs": [],
      "source": [
        "client_secret_input = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Input your client secret\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pzwA6qYt-WP-"
      },
      "outputs": [],
      "source": [
        "user_agent_input = \"buyfromEU_from_u/your_username\" # @param {\"type\":\"string\",\"placeholder\":\"Input your user agent\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2xV3ROa9ogv"
      },
      "source": [
        "# 2. Imports / Setup client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hjfm_FM9j-u"
      },
      "outputs": [],
      "source": [
        "!pip install praw\n",
        "!pip install mistralai\n",
        "\n",
        "import praw\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import ast\n",
        "from mistralai import Mistral\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9l1vyyKZ9zQV"
      },
      "outputs": [],
      "source": [
        "client = praw.Reddit(\n",
        "    client_id=client_id_input,\n",
        "    client_secret=client_secret_input,\n",
        "    user_agent=user_agent_input\n",
        ")\n",
        "subreddit_client = client.subreddit(\"buyfromeu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0wk0aqgdP0-"
      },
      "source": [
        "# Set search words and flairs to check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fQeZf49a1-Z"
      },
      "outputs": [],
      "source": [
        "search_terms = ['alternative', 'alternatives', 'instead', 'swap', 'transfer', 'switch', 'switching', 'check out', 'suggest']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm6v0BdLcgW7"
      },
      "outputs": [],
      "source": [
        "flairs = ['Suggested Product or Service', 'Alternative Product or Service']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVFNM3r3IxP-"
      },
      "source": [
        "# 3. Extract posts relevant to flairs and search terms and save as .csv.\n",
        "### *Optionally, download from files sidebar. Recommended in case you lose progress.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlgIGfpBeFWM"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class Post(BaseModel):\n",
        "  title: str\n",
        "  post_text: str\n",
        "  comments: list\n",
        "  url: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQGBUasPoAt_"
      },
      "outputs": [],
      "source": [
        "def handle_comments(submission):\n",
        "  comments = []\n",
        "  comment_ids = submission.comments\n",
        "  comment_ids.replace_more(limit=50)\n",
        "  for comment in comment_ids.list():\n",
        "    comments.append(comment.body)\n",
        "  return comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AsoJmDBfaLsq"
      },
      "outputs": [],
      "source": [
        "submissions = []\n",
        "\n",
        "for term in search_terms:\n",
        "  for submission in subreddit_client.search(term):\n",
        "    print(\"Working on submission...\")\n",
        "    title = submission.title\n",
        "    post_text = submission.selftext\n",
        "    comments = handle_comments(submission)\n",
        "    url = submission.url\n",
        "\n",
        "    submissions.append(Post(title=title, post_text=post_text, url=url, comments=comments))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CGswyXPhq0mo"
      },
      "outputs": [],
      "source": [
        "for flair in flairs:\n",
        "  print(flair)\n",
        "  for submission in subreddit_client.search(f'flair:\"{flair}\"'):\n",
        "    print(\"Handling submission...\")\n",
        "    title = submission.title\n",
        "    post_text = submission.selftext\n",
        "    comments = handle_comments(submission)\n",
        "    url = submission.url\n",
        "\n",
        "    submissions.append(Post(url=url, comments=comments, post_text=post_text, title=title))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U52l3b8GkjM6"
      },
      "outputs": [],
      "source": [
        "extracted_data = pd.DataFrame([x.dict() for x in submissions])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8ufJXuXtBNs"
      },
      "outputs": [],
      "source": [
        "extracted_data.to_csv(\"bfeu_extracted.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Input Mistral API key (requires paid tier due to data load)"
      ],
      "metadata": {
        "id": "972Mv4m17TDm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "df9KBpImt6dF"
      },
      "outputs": [],
      "source": [
        "mistral_api_key = \"\" # @param {\"type\":\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIeDBnECthlS"
      },
      "source": [
        "# 5. Use Mistral to extract original products and alternatives from each thread."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNMT-KISxpbs"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('bfeu_extracted.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oCm_dBFuuJ5q"
      },
      "outputs": [],
      "source": [
        "!pip install mistralai\n",
        "from mistralai import Mistral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVOLQjnat4RN"
      },
      "outputs": [],
      "source": [
        "mistral_client = Mistral(api_key=mistral_api_key)\n",
        "model = 'mistral-large-latest'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJiddcY3uktn"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "\n",
        "You are a helpful assistant tasked to extract data from reddit threads.\n",
        "You never fabricate data.\n",
        "You dilligently review the reddit threads at hand and extract the data as instructed.\n",
        "\n",
        "Take your time to ensure all the data you extract is correct. Do not fabricate data. If there is no suitable data for you to output, output an empty string or N/A.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "task_prompt = \"\"\"\n",
        "\n",
        "Identify the product being discussed, the American version and European alternative from the reddit thread provided.\n",
        "Take your time to ensure all the data you extract is correct. Do not fabricate data. If there is no suitable data for you to output, output an empty string or N/A.\n",
        "\n",
        "Use the following format in JSON:\n",
        "\n",
        "\"product_type\": the product type mentioned in the reddit threat i.e video streaming service\n",
        "\"american_products\": the american companies or products mentioned in the reddit thread e.g Netflix, Amazon Prime\n",
        "\"european_products\" the european products mentioned in the reddit thread e.g BritBox, RaiPlay\n",
        "\n",
        "Reddit thread: {thread}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdnA_4rE0JHj"
      },
      "outputs": [],
      "source": [
        "dataset = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "misformatted = []"
      ],
      "metadata": {
        "id": "ml7tg7Ek-yAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkKQFZwUxWpH"
      },
      "outputs": [],
      "source": [
        "for index, row in data.iterrows():\n",
        "  try:\n",
        "    thread_data = (\n",
        "        f\"title: {row['title']}\\n\"\n",
        "        f\"post_text: {row['post_text']}\\n\"\n",
        "        f\"comments: {row['comments']}\\n\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_prompt,\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": task_prompt.format(thread=thread_data)\n",
        "            }\n",
        "    ]\n",
        "\n",
        "    chat_response = mistral_client.chat.complete(\n",
        "          model = model,\n",
        "          messages = messages,\n",
        "          response_format = {\n",
        "              \"type\": \"json_object\",\n",
        "          }\n",
        "    )\n",
        "\n",
        "    output = json.loads(chat_response.choices[0].message.content)\n",
        "    dataset = pd.concat([dataset, pd.DataFrame([output])], ignore_index=True)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    misformatted.append(output)\n",
        "    continue"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Save to CSV to clean, format and wrangle later\n",
        "### *Optionally, download from files sidebar. Recommended in case you lose progress.*"
      ],
      "metadata": {
        "id": "Nj4qICCa8P-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_csv('extracted_products.csv')"
      ],
      "metadata": {
        "id": "4010VylS75fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check the dataset out"
      ],
      "metadata": {
        "id": "mopItmtO_UOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "GrTda7VD-jGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Clean and format the dataset\n",
        "Concatenate repeats, drop miscellaneous columns, format data for consistency.\n",
        "\n",
        "We will output two datasets: one with aggregated fields under the same product type (so all american and european coca cola alternatives are grouped, for example) and one where there is a single line per product.\n",
        "\n",
        "This is pure choice to allow flexibility with methods of reviewing and entering data.\n",
        "\n",
        "There could be some improvements made in terms of execution here, but it works well."
      ],
      "metadata": {
        "id": "JiETvW_EIK9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### General formatting and creating our aggregated dataset."
      ],
      "metadata": {
        "id": "HyM8IEAQTIBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('extracted_products.csv')"
      ],
      "metadata": {
        "id": "SukwlNGEHO_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop old columns\n",
        "clean_dataset = dataset[['product_type', 'american_products', 'european_products']]"
      ],
      "metadata": {
        "id": "TdO2MicWHRHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(lst):\n",
        "  \"\"\"Helper function to flatten lists\"\"\"\n",
        "  for item in lst:\n",
        "      if isinstance(item, list):\n",
        "          yield from flatten(item)\n",
        "      else:\n",
        "          yield item"
      ],
      "metadata": {
        "id": "95wLcKXrLKp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace NaN values with \"N/A\"\n",
        "clean_dataset['american_products'] = clean_dataset['american_products'].apply(lambda x: x if isinstance(x, list) else (x if isinstance(x, str) else \"N/A\"))\n",
        "clean_dataset['european_products'] = clean_dataset['european_products'].apply(lambda x: x if isinstance(x, list) else (x if isinstance(x, str) else \"N/A\"))\n"
      ],
      "metadata": {
        "id": "PY63yoc9KjPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert string representations of lists to actual lists\n",
        "clean_dataset['american_products'] = clean_dataset['american_products'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('[') else x)\n",
        "clean_dataset['european_products'] = clean_dataset['european_products'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('[') else x)\n"
      ],
      "metadata": {
        "id": "9uedI8AlLuz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten lists if needed\n",
        "clean_dataset['american_products'] = clean_dataset['american_products'].apply(lambda x: list(flatten([x])) if isinstance(x, list) else [x])\n",
        "clean_dataset['european_products'] = clean_dataset['european_products'].apply(lambda x: list(flatten([x])) if isinstance(x, list) else [x])\n",
        "\n",
        "# Ensure all values in american_products and european_products are lists\n",
        "clean_dataset['american_products'] = clean_dataset['american_products'].apply(lambda x: x.split(', ') if isinstance(x, str) else x)\n",
        "clean_dataset['european_products'] = clean_dataset['european_products'].apply(lambda x: x.split(', ') if isinstance(x, str) else x)\n",
        "\n",
        "# Normalize the strings: convert to lowercase and strip whitespace\n",
        "clean_dataset['american_products'] = clean_dataset['american_products'].apply(lambda x: [item.lower().strip() for item in x] if isinstance(x, list) else x)\n",
        "clean_dataset['european_products'] = clean_dataset['european_products'].apply(lambda x: [item.lower().strip() for item in x] if isinstance(x, list) else x)\n",
        "\n",
        "# Explode the lists to separate rows\n",
        "exploded_dataset = clean_dataset.explode('american_products').explode('european_products')\n"
      ],
      "metadata": {
        "id": "au6OPiRmLUu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by product_type, aggregating unique values in american_products and european_products\n",
        "clean_formatted_dataset = exploded_dataset.groupby('product_type', as_index=False).agg({\n",
        "    'american_products': lambda x: list(set(x)) if \"n/a\" not in x else \"N/A\",\n",
        "    'european_products': lambda x: list(set(x)) if \"n/a\" not in x else \"N/A\"\n",
        "})\n",
        "\n",
        "clean_formatted_dataset"
      ],
      "metadata": {
        "id": "KHrLRCmtLZDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now let's make our single item <> row dataset."
      ],
      "metadata": {
        "id": "LJurY4sQQ70t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exploded_dataset.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "5zCd9BBiPUUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split comma-separated strings into lists, then re-explode.\n",
        "exploded_dataset['american_products'] = exploded_dataset['american_products'].apply(lambda x: x.split(', ') if isinstance(x, str) else x)\n",
        "exploded_dataset['european_products'] = exploded_dataset['european_products'].apply(lambda x: x.split(', ') if isinstance(x, str) else x)\n",
        "exploded_dataset = exploded_dataset.explode('american_products').explode('european_products')"
      ],
      "metadata": {
        "id": "B-fQFxZjQBHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exploded_dataset.drop_duplicates()"
      ],
      "metadata": {
        "id": "2lddLfIUQCH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check your datasets out!\n",
        "*Run this and expand to view.*"
      ],
      "metadata": {
        "id": "OyYRlVhySfTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exploded_dataset.head()"
      ],
      "metadata": {
        "id": "seMgPbipSiUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_formatted_dataset.head()"
      ],
      "metadata": {
        "id": "A3TZqMgySjmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Save the final datasets to csv - make sure to download them from the sidebar!"
      ],
      "metadata": {
        "id": "xnGrVnodMwNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_formatted_dataset.to_csv(\"bfeu_formatted_final.csv\")"
      ],
      "metadata": {
        "id": "ViQqBprQMyyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exploded_dataset.to_csv(\"bfeu_single_line_final.csv\")"
      ],
      "metadata": {
        "id": "x7wsjGKGRIQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "a2xV3ROa9ogv",
        "yVFNM3r3IxP-"
      ],
      "provenance": [],
      "mount_file_id": "1jOl2a3E2jeHAtS0OFjnaBebcst3MZRVK",
      "authorship_tag": "ABX9TyNX9JokDwsUyBWEFjoocUAw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}